{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the baseline configuration of the OpenAI library for Azure OpenAI Service.\n",
    "OPENAI_API_KEY = \"PLEASE_ENTER_YOUR_OWNED_AOAI_SERVICE_KEY\"\n",
    "OPENAI_API_BASE = \"https://PLESAE_ENTER_YOUR_OWNED_AOAI_RESOURCE_NAME.openai.azure.com/\"\n",
    "OPENAI_DEPLOYMENT_NAME = \"PLEASE_ENTER_YOUR_OWNED_AOAI_GPT_MODEL_NAME\"\n",
    "OPENAI_MODEL_NAME = \"text-davinci-003\"\n",
    "OPENAI_EMBEDDING_DEPLOYMENT_NAME = \"PLEASE_ENTER_YOUR_OWNED_AOAI_EMBEDDING_MODEL_NAME\"\n",
    "OPENAI_EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "OPENAI_API_VERSION = \"2023-05-15\"\n",
    "OPENAI_API_TYPE = \"azure\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "openai.api_base = OPENAI_API_BASE\n",
    "openai.api_version = OPENAI_API_VERSION\n",
    "openai.api_type = OPENAI_API_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to interact with Azure OpenAI Embedding Model.\n",
    "embeddings = OpenAIEmbeddings(deployment=OPENAI_EMBEDDING_DEPLOYMENT_NAME, \n",
    "                                openai_api_key=OPENAI_API_KEY, \n",
    "                                model=OPENAI_EMBEDDING_MODEL_NAME, \n",
    "                                openai_api_type=OPENAI_API_TYPE, \n",
    "                                chunk_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Chroma vector store and function to generate embeddings.\n",
    "db = Chroma(persist_directory=\"./chroma_db_a/\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Question Answering chain using the embeddings and the similarity search.\n",
    "chain = load_qa_chain(AzureOpenAI(openai_api_key=OPENAI_API_KEY, \n",
    "                                  deployment_name=OPENAI_DEPLOYMENT_NAME, \n",
    "                                  model_name=OPENAI_MODEL_NAME,\n",
    "                                  openai_api_version=OPENAI_API_VERSION),\n",
    "                                  chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Don Miller had 30 sales.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform first sample of question answering.\n",
    "inquiry = \"How many sales from Don Miller?\"\n",
    "docs = db.similarity_search(inquiry)\n",
    "chain.run(input_documents=docs, question=inquiry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I have collected data on orders placed by customers, including their names, the order date, quantity, order status, order ID, and sales.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform second sample of question answering.\n",
    "inquiry = \"Can you give me a summary of the data you have collected?\"\n",
    "docs = db.similarity_search(inquiry)\n",
    "chain.run(input_documents=docs, question=inquiry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
